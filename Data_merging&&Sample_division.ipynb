{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b65e366-512a-4861-82d9-ed4cf5253700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自动获取的 total_sequence_length: 61145\n",
      "随机选择的负样本用户 (8个): ['12', '15', '21', '16', '7', '20', '23', '29']\n",
      "随机选择的预测用户 (1个): ['35']\n",
      "\n",
      "处理窗口长度 50:\n",
      "已保存 12220 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_50.json\n",
      "数据形状: (12220, 50, 11)\n",
      "已保存 1216 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_50.json\n",
      "数据形状: (1216, 50, 11)\n",
      "已保存 1222 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_50.json\n",
      "数据形状: (1222, 50, 11)\n",
      "窗口长度 50 处理完成:\n",
      "正样本形状: (12220, 50, 11)\n",
      "负样本形状: (1216, 50, 11)\n",
      "预测样本形状: (1222, 50, 11)\n",
      "\n",
      "处理窗口长度 100:\n",
      "已保存 6105 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_100.json\n",
      "数据形状: (6105, 100, 11)\n",
      "已保存 608 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_100.json\n",
      "数据形状: (608, 100, 11)\n",
      "已保存 610 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_100.json\n",
      "数据形状: (610, 100, 11)\n",
      "窗口长度 100 处理完成:\n",
      "正样本形状: (6105, 100, 11)\n",
      "负样本形状: (608, 100, 11)\n",
      "预测样本形状: (610, 100, 11)\n",
      "\n",
      "处理窗口长度 150:\n",
      "已保存 4067 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_150.json\n",
      "数据形状: (4067, 150, 11)\n",
      "已保存 400 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_150.json\n",
      "数据形状: (400, 150, 11)\n",
      "已保存 406 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_150.json\n",
      "数据形状: (406, 150, 11)\n",
      "窗口长度 150 处理完成:\n",
      "正样本形状: (4067, 150, 11)\n",
      "负样本形状: (400, 150, 11)\n",
      "预测样本形状: (406, 150, 11)\n",
      "\n",
      "处理窗口长度 200:\n",
      "已保存 3048 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_200.json\n",
      "数据形状: (3048, 200, 11)\n",
      "已保存 304 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_200.json\n",
      "数据形状: (304, 200, 11)\n",
      "已保存 304 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_200.json\n",
      "数据形状: (304, 200, 11)\n",
      "窗口长度 200 处理完成:\n",
      "正样本形状: (3048, 200, 11)\n",
      "负样本形状: (304, 200, 11)\n",
      "预测样本形状: (304, 200, 11)\n",
      "\n",
      "处理窗口长度 250:\n",
      "已保存 2436 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_250.json\n",
      "数据形状: (2436, 250, 11)\n",
      "已保存 240 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_250.json\n",
      "数据形状: (240, 250, 11)\n",
      "已保存 243 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_250.json\n",
      "数据形状: (243, 250, 11)\n",
      "窗口长度 250 处理完成:\n",
      "正样本形状: (2436, 250, 11)\n",
      "负样本形状: (240, 250, 11)\n",
      "预测样本形状: (243, 250, 11)\n",
      "\n",
      "处理窗口长度 300:\n",
      "已保存 2029 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_300.json\n",
      "数据形状: (2029, 300, 11)\n",
      "已保存 200 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_300.json\n",
      "数据形状: (200, 300, 11)\n",
      "已保存 202 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_300.json\n",
      "数据形状: (202, 300, 11)\n",
      "窗口长度 300 处理完成:\n",
      "正样本形状: (2029, 300, 11)\n",
      "负样本形状: (200, 300, 11)\n",
      "预测样本形状: (202, 300, 11)\n",
      "\n",
      "处理窗口长度 350:\n",
      "已保存 1738 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_350.json\n",
      "数据形状: (1738, 350, 11)\n",
      "已保存 168 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_350.json\n",
      "数据形状: (168, 350, 11)\n",
      "已保存 173 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_350.json\n",
      "数据形状: (173, 350, 11)\n",
      "窗口长度 350 处理完成:\n",
      "正样本形状: (1738, 350, 11)\n",
      "负样本形状: (168, 350, 11)\n",
      "预测样本形状: (173, 350, 11)\n",
      "\n",
      "处理窗口长度 400:\n",
      "已保存 1519 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\positive_samples_user9_400.json\n",
      "数据形状: (1519, 400, 11)\n",
      "已保存 144 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\negative_samples_user9_400.json\n",
      "数据形状: (144, 400, 11)\n",
      "已保存 151 个样本到 D:/论文数据/mouse/data\\processed_data_user9\\predict_samples_user9_400.json\n",
      "数据形状: (151, 400, 11)\n",
      "窗口长度 400 处理完成:\n",
      "正样本形状: (1519, 400, 11)\n",
      "负样本形状: (144, 400, 11)\n",
      "预测样本形状: (151, 400, 11)\n",
      "\n",
      "所有窗口长度处理完成\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, root_dir: str, output_dir: str, sequence_lengths: List[int], \n",
    "                 slide_ratio: float, pos_neg_ratio: int, pos_user_id: str, \n",
    "                 pos_csv_path: str, columns: List[str] = None):\n",
    "        \"\"\"\n",
    "        初始化数据处理器\n",
    "\n",
    "        Args:\n",
    "            root_dir: 根目录路径\n",
    "            output_dir: 输出目录路径\n",
    "            sequence_lengths: 窗口长度列表（每个样本包含的数据点数量）\n",
    "            slide_ratio: 滑动窗口的移动比例\n",
    "            pos_neg_ratio: 正负样本比例\n",
    "            pos_user_id: 正样本用户ID\n",
    "            pos_csv_path: 正样本CSV文件路径\n",
    "            columns: 需要提取的列名\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.base_output_dir = output_dir\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "        self.slide_ratio = slide_ratio\n",
    "        self.pos_neg_ratio = pos_neg_ratio\n",
    "        self.pos_user_id = pos_user_id\n",
    "        self.pos_csv_path = pos_csv_path\n",
    "        \n",
    "        if columns is None:\n",
    "            self.columns = ['x', 'y', 'velocity', 'acceleration', 'curvature',\n",
    "                           'angle_change', 'x_velocity', 'y_velocity', \n",
    "                           'x_acceleration', 'y_acceleration', 'press_duration']\n",
    "        else:\n",
    "            self.columns = columns\n",
    "        \n",
    "        # 自动获取 total_sequence_length\n",
    "        self.total_sequence_length = self._get_total_sequence_length()\n",
    "        print(f\"自动获取的 total_sequence_length: {self.total_sequence_length}\")\n",
    "        \n",
    "        # 为每个窗口长度创建单独的输出目录\n",
    "        self.output_dirs = {}\n",
    "        for seq_len in self.sequence_lengths:\n",
    "            dir_path = os.path.join(output_dir, f\"processed_data_user{pos_user_id}\")\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            self.output_dirs[seq_len] = dir_path\n",
    "        \n",
    "        # 为每个窗口长度存储统计信息\n",
    "        self.sample_stats = {seq_len: defaultdict(int) for seq_len in sequence_lengths}\n",
    "\n",
    "    def _get_total_sequence_length(self) -> int:\n",
    "        \"\"\"\n",
    "        自动获取 total_sequence_length，基于 pos_csv_path 的数据行数（不包括标题）\n",
    "\n",
    "        Returns:\n",
    "            int: 总序列长度\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.pos_csv_path)\n",
    "            # 确保所有需要的列都存在\n",
    "            missing_columns = [col for col in self.columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                raise ValueError(f\"正样本数据文件缺少以下列: {missing_columns}\")\n",
    "            total_length = len(df)\n",
    "            return total_length\n",
    "        except Exception as e:\n",
    "            print(f\"获取 total_sequence_length 时出错: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load_user_data(self, user_id: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        加载指定用户的数据文件\n",
    "\n",
    "        Args:\n",
    "            user_id: 用户ID\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 用户的数据\n",
    "        \"\"\"\n",
    "        try:\n",
    "            user_dir = os.path.join(self.root_dir, f\"user{user_id}\")\n",
    "            \n",
    "            if not os.path.exists(user_dir):\n",
    "                raise FileNotFoundError(f\"找不到用户 {user_id} 的目录: {user_dir}\")\n",
    "            \n",
    "            csv_files = [f for f in os.listdir(user_dir) if f.endswith('.csv')]\n",
    "            \n",
    "            if not csv_files:\n",
    "                raise FileNotFoundError(f\"用户 {user_id} 的目录中没有CSV文件: {user_dir}\")\n",
    "            \n",
    "            csv_file = sorted(csv_files)[-1]\n",
    "            file_path = os.path.join(user_dir, csv_file)\n",
    "            \n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            missing_columns = [col for col in self.columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                raise ValueError(f\"数据文件缺少以下列: {missing_columns}\")\n",
    "                \n",
    "            if len(df) > self.total_sequence_length:\n",
    "                df = df.iloc[:self.total_sequence_length]\n",
    "                \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"加载用户 {user_id} 数据时出错: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load_positive_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        加载正样本的数据文件（从指定的CSV路径）\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 正样本的数据\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.pos_csv_path):\n",
    "                raise FileNotFoundError(f\"正样本的CSV文件不存在: {self.pos_csv_path}\")\n",
    "            \n",
    "            df = pd.read_csv(self.pos_csv_path)\n",
    "            \n",
    "            missing_columns = [col for col in self.columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                raise ValueError(f\"正样本数据文件缺少以下列: {missing_columns}\")\n",
    "                \n",
    "            if len(df) > self.total_sequence_length:\n",
    "                df = df.iloc[:self.total_sequence_length]\n",
    "                \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"加载正样本数据时出错: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def create_sequences(self, df: pd.DataFrame, user_id: str, sequence_length: int) -> np.ndarray:\n",
    "        \"\"\"创建指定窗口长度的样本序列\"\"\"\n",
    "        sequences = []\n",
    "        data = df[self.columns].values\n",
    "        \n",
    "        slide_window = max(1, int(sequence_length * self.slide_ratio))\n",
    "        \n",
    "        max_start_idx = min(self.total_sequence_length - sequence_length, \n",
    "                          len(data) - sequence_length)\n",
    "        \n",
    "        for i in range(0, max_start_idx + 1, slide_window):\n",
    "            sequence = data[i:i + sequence_length]\n",
    "            if len(sequence) == sequence_length:\n",
    "                sequences.append(sequence)\n",
    "        \n",
    "        sequences = np.array(sequences)\n",
    "        self.sample_stats[sequence_length][f\"user{user_id}\"] = len(sequences)\n",
    "        \n",
    "        return sequences\n",
    "\n",
    "    def save_samples(self, samples: np.ndarray, filename: str, sequence_length: int):\n",
    "        \"\"\"\n",
    "        保存样本到JSON文件\n",
    "\n",
    "        Args:\n",
    "            samples: 形状为 (n_samples, sequence_length, n_features) 的样本数组\n",
    "            filename: 文件名前缀\n",
    "            sequence_length: 序列长度\n",
    "        \"\"\"\n",
    "        if len(samples) == 0:\n",
    "            print(f\"警告: {filename} 没有样本可以保存\")\n",
    "            return\n",
    "            \n",
    "        filename_prefix = filename.split('_')[0]\n",
    "        output_path = os.path.join(\n",
    "            self.output_dirs[sequence_length], \n",
    "            f\"{filename_prefix}_samples_user{self.pos_user_id}_{sequence_length}.json\"\n",
    "        )\n",
    "        \n",
    "        # 构建JSON数据结构\n",
    "        data = {\n",
    "            'metadata': {\n",
    "                'shape': list(samples.shape),\n",
    "                'feature_names': self.columns,\n",
    "                'sequence_length': sequence_length\n",
    "            },\n",
    "            'samples': []\n",
    "        }\n",
    "        \n",
    "        # 将每个样本转换为列表并添加到samples列表中\n",
    "        for sample in samples:\n",
    "            # sample的形状是(sequence_length, n_features)\n",
    "            sample_list = []\n",
    "            for timestep in sample:\n",
    "                # timestep的形状是(n_features,)\n",
    "                feature_dict = {feature: float(value) for feature, value in zip(self.columns, timestep)}\n",
    "                sample_list.append(feature_dict)\n",
    "            data['samples'].append(sample_list)\n",
    "        \n",
    "        # 保存为JSON文件\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "            \n",
    "        print(f\"已保存 {len(samples)} 个样本到 {output_path}\")\n",
    "        print(f\"数据形状: {samples.shape}\")\n",
    "\n",
    "    def load_samples(self, filepath: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        从JSON文件加载样本数据\n",
    "\n",
    "        Args:\n",
    "            filepath: JSON文件路径\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 形状为 (n_samples, sequence_length, n_features) 的数组\n",
    "        \"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # 从metadata获取信息\n",
    "        shape = data['metadata']['shape']\n",
    "        feature_names = data['metadata']['feature_names']\n",
    "        \n",
    "        # 将JSON数据转换回numpy数组\n",
    "        samples_list = []\n",
    "        for sample in data['samples']:\n",
    "            # 转换单个样本\n",
    "            sample_array = np.zeros((len(sample), len(feature_names)))\n",
    "            for i, timestep in enumerate(sample):\n",
    "                for j, feature in enumerate(feature_names):\n",
    "                    sample_array[i, j] = timestep[feature]\n",
    "            samples_list.append(sample_array)\n",
    "        \n",
    "        # 转换为numpy数组并确保形状正确\n",
    "        samples = np.array(samples_list)\n",
    "        assert samples.shape == tuple(shape), f\"加载的数据形状 {samples.shape} 与预期形状 {shape} 不符\"\n",
    "        \n",
    "        print(f\"已加载数据，形状: {samples.shape}\")\n",
    "        return samples\n",
    "\n",
    "    def save_sample_stats(self, sequence_length: int):\n",
    "        \"\"\"保存样本统计信息\"\"\"\n",
    "        stats_path = os.path.join(self.output_dirs[sequence_length], 'sample_statistics.txt')\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"样本统计信息:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            f.write(f\"窗口长度: {sequence_length}\\n\")\n",
    "            f.write(f\"总序列长度: {self.total_sequence_length}\\n\")\n",
    "            f.write(f\"滑动步长: {max(1, int(sequence_length * self.slide_ratio))}\\n\\n\")\n",
    "            \n",
    "            f.write(\"每个用户可用的样本总数:\\n\")\n",
    "            for user_id, count in sorted(self.sample_stats[sequence_length].items()):\n",
    "                if not user_id.endswith('_selected'):\n",
    "                    f.write(f\"{user_id}: {count}\\n\")\n",
    "            \n",
    "            f.write(\"\\n实际选择的样本数:\\n\")\n",
    "            for user_id, count in sorted(self.sample_stats[sequence_length].items()):\n",
    "                if user_id.endswith('_selected'):\n",
    "                    f.write(f\"{user_id.replace('_selected', '')}: {count}\\n\")\n",
    "\n",
    "    def process_data(self, neg_user_ids: List[str], \n",
    "                    pred_user_ids: List[str]) -> dict:\n",
    "        \"\"\"处理所有数据\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for sequence_length in self.sequence_lengths:\n",
    "            print(f\"\\n处理窗口长度 {sequence_length}:\")\n",
    "            \n",
    "            # 获取正样本\n",
    "            df_pos = self.load_positive_data()\n",
    "            positive_samples = self.create_sequences(df_pos, self.pos_user_id, sequence_length)\n",
    "            \n",
    "            if len(positive_samples) == 0:\n",
    "                print(f\"警告: 窗口长度 {sequence_length} 未能生成正样本\")\n",
    "                continue\n",
    "\n",
    "            n_positive = len(positive_samples)\n",
    "            n_negative = max(1, n_positive // self.pos_neg_ratio)\n",
    "            n_predict = max(1, n_positive // self.pos_neg_ratio)\n",
    "            \n",
    "            # 获取负样本\n",
    "            negative_samples = []\n",
    "            samples_per_user = max(1, n_negative // len(neg_user_ids))\n",
    "            for user_id in neg_user_ids:\n",
    "                df_neg = self.load_user_data(user_id)\n",
    "                sequences = self.create_sequences(df_neg, user_id, sequence_length)\n",
    "                if len(sequences) >= samples_per_user:\n",
    "                    indices = np.linspace(0, len(sequences)-1, samples_per_user, dtype=int)\n",
    "                    selected_samples = sequences[indices]\n",
    "                else:\n",
    "                    indices = np.random.choice(len(sequences), samples_per_user, replace=True)\n",
    "                    selected_samples = sequences[indices]\n",
    "                negative_samples.extend(selected_samples)\n",
    "            negative_samples = np.array(negative_samples)\n",
    "            \n",
    "            # 获取预测样本\n",
    "            predict_samples = []\n",
    "            samples_per_user = max(1, n_predict // len(pred_user_ids))\n",
    "            for user_id in pred_user_ids:\n",
    "                df_pred = self.load_user_data(user_id)\n",
    "                sequences = self.create_sequences(df_pred, user_id, sequence_length)\n",
    "                if len(sequences) >= samples_per_user:\n",
    "                    indices = np.linspace(0, len(sequences)-1, samples_per_user, dtype=int)\n",
    "                    selected_samples = sequences[indices]\n",
    "                else:\n",
    "                    indices = np.random.choice(len(sequences), samples_per_user, replace=True)\n",
    "                    selected_samples = sequences[indices]\n",
    "                predict_samples.extend(selected_samples)\n",
    "            predict_samples = np.array(predict_samples)\n",
    "            \n",
    "            # 保存样本\n",
    "            self.save_samples(positive_samples, 'positive', sequence_length)\n",
    "            self.save_samples(negative_samples, 'negative', sequence_length)\n",
    "            self.save_samples(predict_samples, 'predict', sequence_length)\n",
    "            \n",
    "            # 保存统计信息\n",
    "            self.save_sample_stats(sequence_length)\n",
    "            \n",
    "            results[sequence_length] = {\n",
    "                'positive': positive_samples,\n",
    "                'negative': negative_samples,\n",
    "                'predict': predict_samples\n",
    "            }\n",
    "            \n",
    "            print(f\"窗口长度 {sequence_length} 处理完成:\")\n",
    "            print(f\"正样本形状: {positive_samples.shape}\")\n",
    "            print(f\"负样本形状: {negative_samples.shape}\")\n",
    "            print(f\"预测样本形状: {predict_samples.shape}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def get_random_users(all_users: List[str], pos_user_id: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    从所有用户中随机选择负样本用户和预测用户\n",
    "    \n",
    "    Args:\n",
    "        all_users: 所有可用的用户ID列表\n",
    "        pos_user_id: 正样本用户ID\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[List[str], List[str]]: (负样本用户列表, 预测用户列表)\n",
    "    \"\"\"\n",
    "    # 移除正样本用户\n",
    "    available_users = [uid for uid in all_users if uid != pos_user_id]\n",
    "    \n",
    "    # 首先随机决定预测用户数量（1或2）\n",
    "    n_pred = np.random.randint(1, 3)\n",
    "    \n",
    "    # 根据预测用户数量确定负样本用户数量\n",
    "    n_neg = 8 if n_pred == 1 else 7\n",
    "    \n",
    "    # 随机打乱可用用户顺序\n",
    "    shuffled_users = np.random.permutation(available_users)\n",
    "    \n",
    "    # 分配用户\n",
    "    neg_users = shuffled_users[:n_neg].tolist()\n",
    "    pred_users = shuffled_users[n_neg:n_neg+n_pred].tolist()\n",
    "    \n",
    "    return neg_users, pred_users\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = r\"D:/datauser/NEW_merged_files\"\n",
    "    output_dir = r\"D:/论文数据/mouse/data\"\n",
    "    sequence_lengths = [50, 100, 150, 200, 250, 300,350,400]\n",
    "    slide_ratio = 0.1\n",
    "    pos_neg_ratio = 10\n",
    "    pos_user_id = \"9\"\n",
    "    pos_csv_path = f\"user{pos_user_id}_combined_output.csv\"\n",
    "\n",
    "    # 所有可用的用户ID\n",
    "    all_user_ids = [\"7\", \"9\", \"12\", \"15\", \"16\", \"20\", \"21\", \"23\", \"29\", \"35\"]\n",
    "    \n",
    "    try:\n",
    "        processor = DataProcessor(\n",
    "            root_dir=root_dir,\n",
    "            output_dir=output_dir,\n",
    "            sequence_lengths=sequence_lengths,\n",
    "            slide_ratio=slide_ratio,\n",
    "            pos_neg_ratio=pos_neg_ratio,\n",
    "            pos_user_id=pos_user_id,\n",
    "            pos_csv_path=pos_csv_path\n",
    "        )\n",
    "\n",
    "        # 随机选择用户\n",
    "        neg_user_ids, pred_user_ids = get_random_users(all_user_ids, pos_user_id)\n",
    "        \n",
    "        print(f\"随机选择的负样本用户 ({len(neg_user_ids)}个): {neg_user_ids}\")\n",
    "        print(f\"随机选择的预测用户 ({len(pred_user_ids)}个): {pred_user_ids}\")\n",
    "\n",
    "        results = processor.process_data(neg_user_ids, pred_user_ids)\n",
    "        print(\"\\n所有窗口长度处理完成\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d239f5b-4510-4c8a-ada7-dc8e24252446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理文件: D:/datauser/NEW_Data_files/user9/session_0335985747.csv，需要提取 7800 行数据...\n",
      "成功从 D:/datauser/NEW_Data_files/user9/session_0335985747.csv 提取 7800 行数据。\n",
      "正在处理文件: D:/datauser/NEW_Data_files/user9/session_3390119815.csv，需要提取 8725 行数据...\n",
      "成功从 D:/datauser/NEW_Data_files/user9/session_3390119815.csv 提取 8725 行数据。\n",
      "正在处理文件: D:/datauser/NEW_Data_files/user9/session_3879637058.csv，需要提取 11221 行数据...\n",
      "成功从 D:/datauser/NEW_Data_files/user9/session_3879637058.csv 提取 11221 行数据。\n",
      "正在处理文件: D:/datauser/NEW_Data_files/user9/session_4373781904.csv，需要提取 8435 行数据...\n",
      "成功从 D:/datauser/NEW_Data_files/user9/session_4373781904.csv 提取 8435 行数据。\n",
      "正在处理文件: D:/datauser/NEW_Data_files/user9/session_5155383252.csv，需要提取 8200 行数据...\n",
      "成功从 D:/datauser/NEW_Data_files/user9/session_5155383252.csv 提取 8200 行数据。\n",
      "正在处理文件: D:/datauser/NEW_Data_files/user9/session_7285432516.csv，需要提取 8545 行数据...\n",
      "成功从 D:/datauser/NEW_Data_files/user9/session_7285432516.csv 提取 8545 行数据。\n",
      "正在处理文件: D:/datauser/NEW_Data_files/user9/session_8764610836.csv，需要提取 8219 行数据...\n",
      "成功从 D:/datauser/NEW_Data_files/user9/session_8764610836.csv 提取 8219 行数据。\n",
      "所有数据已成功合并并保存到 user9_combined_output.csv。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_rows(csv_path, num_rows):\n",
    "    \"\"\"\n",
    "    从 CSV 文件的开头提取指定数量的连续行，确保不少于要求的行数\n",
    "    \"\"\"\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.isfile(csv_path):\n",
    "        raise FileNotFoundError(f\"文件未找到: {csv_path}\")\n",
    "    \n",
    "    # 先读取 CSV 文件的总行数（不包括标题）\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f) - 1  # 减去标题行\n",
    "    \n",
    "    if total_lines < num_rows:\n",
    "        raise ValueError(f\"文件 {csv_path} 的总行数 ({total_lines}) 少于要求的行数 ({num_rows})\")\n",
    "    \n",
    "    # 设置起始行为0，从头开始提取\n",
    "    start_row = 0\n",
    "    \n",
    "    # 使用 pandas 读取指定行\n",
    "    # skiprows=1 跳过标题行，nrows=num_rows 读取指定的行数\n",
    "    df = pd.read_csv(csv_path, skiprows=range(1, start_row + 1), nrows=num_rows)\n",
    "    return df\n",
    "\n",
    "def combine_csvs(csv_requests, output_csv):\n",
    "    \"\"\"\n",
    "    提取多个 CSV 文件的数据并合并\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    header_saved = False  # 标记是否已经保存标题行\n",
    "    \n",
    "    for request in csv_requests:\n",
    "        csv_path = request['path']\n",
    "        num_rows = request['rows']\n",
    "        \n",
    "        print(f\"正在处理文件: {csv_path}，需要提取 {num_rows} 行数据...\")\n",
    "        \n",
    "        try:\n",
    "            df = extract_rows(csv_path, num_rows)\n",
    "            if not header_saved:\n",
    "                dataframes.append(df)\n",
    "                header_saved = True\n",
    "            else:\n",
    "                dataframes.append(df)\n",
    "            print(f\"成功从 {csv_path} 提取 {num_rows} 行数据。\")\n",
    "        except (FileNotFoundError, ValueError) as e:\n",
    "            print(e)\n",
    "            print(f\"跳过文件: {csv_path}。\\n\")\n",
    "    \n",
    "    if dataframes:\n",
    "        # 竖向拼接所有数据，保留一个标题行\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        combined_df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "        print(f\"所有数据已成功合并并保存到 {output_csv}。\")\n",
    "    else:\n",
    "        print(\"没有数据被提取和合并。\")\n",
    "\n",
    "def main():\n",
    "    # 配置部分\n",
    "    output_csv = 'user9_combined_output.csv'  # 输出的 CSV 文件名\n",
    "    \n",
    "    # 定义要处理的 CSV 文件路径及对应需要提取的行数\n",
    "    # 请将这里的路径替换为您的实际 CSV 文件路径\n",
    "    csv_requests = [\n",
    "        {'path': 'D:/datauser/NEW_Data_files/user9/session_0335985747.csv', 'rows': 7800},\n",
    "        {'path': 'D:/datauser/NEW_Data_files/user9/session_3390119815.csv', 'rows': 8725},\n",
    "        {'path': 'D:/datauser/NEW_Data_files/user9/session_3879637058.csv', 'rows': 11221},\n",
    "        {'path': 'D:/datauser/NEW_Data_files/user9/session_4373781904.csv', 'rows': 8435},\n",
    "        {'path': 'D:/datauser/NEW_Data_files/user9/session_5155383252.csv', 'rows': 8200},\n",
    "        {'path': 'D:/datauser/NEW_Data_files/user9/session_7285432516.csv', 'rows': 8545},\n",
    "        {'path': 'D:/datauser/NEW_Data_files/user9/session_8764610836.csv', 'rows': 8219}\n",
    "        # 添加更多的 CSV 文件和对应的行数\n",
    "    ]\n",
    "    \n",
    "    # 可选：设置随机种子以确保可重复性\n",
    "    # random.seed(42)\n",
    "    \n",
    "    combine_csvs(csv_requests, output_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fb026-38eb-44f9-b29b-b9f38d6bcaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_0335985747.csv\tsession_3390119815.csv\tsession_3879637058.csv\tsession_4373781904.csv\tsession_5155383252.csv\tsession_7285432516.csv\tsession_8764610836.csv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
